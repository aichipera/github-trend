# [AI的“玻璃天花板”：为何我们离真正的AGI还很遥远？](20250707-agi-is-not-right-around-the-corner.mp3)

> **【编者按】**
> 我们正处在一个AI的“镀金时代”：一方面，AI在特定任务上的表现令人惊艳，甚至让人产生“通用智能”已近在咫尺的错觉；另一方面，任何试图将其深度整合进工作流的人，又会迅速撞上它“学不会、教不懂”的隐形墙壁。播主Dwarkesh Patel的文章和Hacker News上的热议，恰好揭示了这一核心矛盾。本文将深入探讨阻碍AGI到来的两大瓶颈——“持续学习”与“可靠的计算机代理”，并结合社区的多元视角，为你描绘一幅更清醒、更立体的AI发展路线图。AGI究竟是下一个路口的奇迹，还是需要数年乃至数十年才能跨越的鸿沟？这不仅是技术问题，更关乎我们的期待与现实。

“事情发生所需的时间比你想象的要长，然后它们发生的速度又比你想象的要快。”这句名言完美捕捉了当前我们对通用人工智能（AGI）的复杂心态。一方面，模型的能力日新月异，让人感觉奇点将至；另一方面，冷静的观察者们则指出了那些看似微小却极为顽固的瓶颈。

在一篇博文[《Why I don’t think AGI is right around the corner》](https://www.dwarkesh.com/p/timelines-june-2025)中，知名科技播主Dwarkesh Patel分享了他对AGI时间线的审慎看法，其观点在Hacker News上引发了广泛共鸣和激烈辩论。他认为，尽管AI取得了魔法般的进步，但两个核心障碍使其远未达到“即将来临”的程度。

## **瓶颈一：无法逾越的“持续学习”鸿沟**

这是Patel提出的最核心的论点，也触动了无数开发者的痛点。他指出，“LLM不会像人类一样随着时间的推移而进步。缺乏持续学习是一个巨大无比的问题。”

他用一个绝妙的比喻来形容这种困境：教一个孩子吹萨克斯风，你会让她不断尝试、倾听、调整。而我们“教”AI的方式，则像是让一个学生试一次，一旦犯错，就打发他走，然后为下一个学生写下长篇的、详尽的修改指南。无论这份指南（System Prompt）多么精妙，下一个学生依然是从零开始，永远无法积累起肌肉记忆和微妙的直觉。

这种“一次性”的交互模式，使得AI更像一个能力超群但毫无记忆的“克隆人军队”，而不是一个能与你共同成长的“学徒”。你在一次会话中费尽心机教会它的风格偏好和微妙技巧，在下一次会-话开始时便烟消云散。正如Hacker News上一位用户所说，这让AI成了一个“聪明的白痴”，一个“永远不会从错误中学习的自负天才”。

## **瓶颈二：步履维艰的“计算机代理”**

当Anthropic的研究员预测明年年底我们将拥有可靠的计算机使用代理（能帮你自动报税的AI）时，Patel表示了强烈的怀疑。他认为，这类任务的实现难度被严重低估了。

首先，任务周期长，反馈稀疏。AI可能需要执行两小时的任务才能知道结果是否正确，这极大地减慢了迭代速度。其次，我们缺乏大规模、高质量的[多模态计算机使用预训练数据](https://www.mechanize.work/blog/how-to-fully-automate-software-engineering/)。正如Patel引用的一句话：“想象一下用1980年所有的文本数据来训练GPT-4——即便算力足够，数据也远远不够。”最后，即使是看似简单的算法创新也需要漫长的打磨，更何况是“计算机使用”这个数据更少、模态更复杂的“无人区”。

这并非否定当前AI的能力。Patel也承认，看到模型能进行复杂的逻辑推理，会让人由衷感叹“它真的在思考”。但这种“婴儿般的通用智能”与一个能够自主学习、可靠执行长期复杂任务的AGI之间，还隔着巨大的技术鸿沟。

## **当下的狂热与未来的图景**

Hacker News的讨论进一步丰富了这一图景。有人认为，所谓“AGI”的定义本就模糊，争论其何时到来就像在讨论空中楼阁。也有人一针见血地指出，当前AI的许多失败，如算不对单词里的字母（“New York”里到底有没有W？），根源在于BPE等技术细节，但这恰恰说明了它离真正的理解还差得很远。

更有趣的是“Dwarkesh问题”的重提：“为什么AI记住了几乎全部人类知识，却未能做出任何一个原创性的科学发现？” 这直指AI缺乏真正的连接、洞察和创造能力。

然而，正是这些瓶颈，让Patel对AI的远期未来“异常看好”。他预测，一旦我们解决了持续学习问题，AI将迎来真正的“智能爆炸”。一个能在线学习的AI，可以通过吸收全球所有岗位的数据，迅速成为功能上的“超级智能”。

根据他的预测，我们或许在2028年能看到AI处理复杂的报税任务，而在2032年，AI或许才能像人类一样“在岗学习”。这个时间表呼应了他的核心观点：AI的发展由[算力规模驱动，而这种指数增长不可持续](https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year)，若本十年内无法突破，AGI的到来概率将大幅降低。

## **那么，你呢？**

在你的工作和生活中，你是否也感受到了AI这种“既聪明又愚蠢”的矛盾特质？你觉得它更像一个能力超群、随叫随到的工具，还是一个让你时常因其“不开窍”而感到沮丧的实习生？欢迎在评论区分享你的经历和看法。